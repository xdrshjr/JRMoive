# AIçŸ­å‰§è‡ªåŠ¨åŒ–ç”Ÿæˆç³»ç»Ÿå¼€å‘æ•™ç¨‹ï¼ˆç¬¬5éƒ¨åˆ†ï¼‰
## å¸¸è§é—®é¢˜ä¸é¡¹ç›®éƒ¨ç½²

---

## ç›®å½•

1. [å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ](#1-å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ)
   - 1.1 [APIç›¸å…³é—®é¢˜](#11-apiç›¸å…³é—®é¢˜)
   - 1.2 [è§†é¢‘å¤„ç†é—®é¢˜](#12-è§†é¢‘å¤„ç†é—®é¢˜)
   - 1.3 [æ€§èƒ½é—®é¢˜](#13-æ€§èƒ½é—®é¢˜)
   - 1.4 [ç¯å¢ƒé…ç½®é—®é¢˜](#14-ç¯å¢ƒé…ç½®é—®é¢˜)
2. [æµ‹è¯•ä¸è´¨é‡ä¿è¯](#2-æµ‹è¯•ä¸è´¨é‡ä¿è¯)
   - 2.1 [å•å…ƒæµ‹è¯•](#21-å•å…ƒæµ‹è¯•)
   - 2.2 [é›†æˆæµ‹è¯•](#22-é›†æˆæµ‹è¯•)
   - 2.3 [æ€§èƒ½æµ‹è¯•](#23-æ€§èƒ½æµ‹è¯•)
3. [é¡¹ç›®éƒ¨ç½²](#3-é¡¹ç›®éƒ¨ç½²)
   - 3.1 [æœ¬åœ°éƒ¨ç½²](#31-æœ¬åœ°éƒ¨ç½²)
   - 3.2 [Dockeréƒ¨ç½²](#32-dockeréƒ¨ç½²)
   - 3.3 [äº‘æœåŠ¡å™¨éƒ¨ç½²](#33-äº‘æœåŠ¡å™¨éƒ¨ç½²)
4. [ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–](#4-ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–)
   - 4.1 [å®‰å…¨æ€§åŠ å›º](#41-å®‰å…¨æ€§åŠ å›º)
   - 4.2 [ç›‘æ§ä¸å‘Šè­¦](#42-ç›‘æ§ä¸å‘Šè­¦)
   - 4.3 [æ‰©å±•æ€§è®¾è®¡](#43-æ‰©å±•æ€§è®¾è®¡)
5. [é™„å½•](#5-é™„å½•)
   - 5.1 [å®Œæ•´é¡¹ç›®ç¤ºä¾‹](#51-å®Œæ•´é¡¹ç›®ç¤ºä¾‹)
   - 5.2 [APIæ–‡æ¡£å‚è€ƒ](#52-apiæ–‡æ¡£å‚è€ƒ)
   - 5.3 [æ‰©å±•é˜…è¯»](#53-æ‰©å±•é˜…è¯»)

---

## 1. å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### 1.1 APIç›¸å…³é—®é¢˜

#### é—®é¢˜1ï¼šNano Banana Pro APIè°ƒç”¨å¤±è´¥

**ç—‡çŠ¶ï¼š**
```
httpx.HTTPStatusError: 401 Unauthorized
```

**åŸå› ä¸è§£å†³æ–¹æ¡ˆï¼š**

```python
# é—®é¢˜è¯Šæ–­è„šæœ¬
import asyncio
from services.nano_banana_service import NanoBananaService
from config.settings import settings

async def diagnose_nano_banana():
    """è¯Šæ–­Nano Banana APIè¿æ¥"""

    print("ğŸ” æ£€æŸ¥Nano Banana Proé…ç½®...")

    # æ£€æŸ¥1ï¼šAPIå¯†é’¥æ˜¯å¦å­˜åœ¨
    if not settings.nano_banana_api_key:
        print("âŒ APIå¯†é’¥æœªé…ç½®")
        print("è§£å†³æ–¹æ¡ˆï¼šåœ¨.envæ–‡ä»¶ä¸­è®¾ç½®NANO_BANANA_API_KEY")
        return

    print(f"âœ… APIå¯†é’¥å·²é…ç½®: {settings.nano_banana_api_key[:10]}...")

    # æ£€æŸ¥2ï¼šåŸºç¡€URLæ˜¯å¦æ­£ç¡®
    print(f"ğŸ“¡ åŸºç¡€URL: {settings.nano_banana_base_url}")

    # æ£€æŸ¥3ï¼šæµ‹è¯•APIè°ƒç”¨
    async with NanoBananaService() as service:
        try:
            result = await service.generate_image(
                prompt="test image",
                width=512,
                height=512
            )
            print("âœ… APIè°ƒç”¨æˆåŠŸ")
            print(f"å“åº”: {result}")

        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            print("\nå¯èƒ½çš„åŸå› ï¼š")
            print("1. APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ")
            print("2. è´¦æˆ·ä½™é¢ä¸è¶³")
            print("3. APIåŸºç¡€URLé…ç½®é”™è¯¯")
            print("4. ç½‘ç»œè¿æ¥é—®é¢˜")

if __name__ == "__main__":
    asyncio.run(diagnose_nano_banana())
```

**å¸¸è§è§£å†³æ–¹æ¡ˆï¼š**

1. **APIå¯†é’¥é”™è¯¯**
   ```bash
   # é‡æ–°è·å–APIå¯†é’¥
   # 1. ç™»å½•Nano Banana Proæ§åˆ¶å°
   # 2. è¿›å…¥APIç®¡ç† â†’ åˆ›å»ºæ–°å¯†é’¥
   # 3. æ›´æ–°.envæ–‡ä»¶
   NANO_BANANA_API_KEY=your_new_api_key
   ```

2. **APIç«¯ç‚¹å˜æ›´**
   ```python
   # æ£€æŸ¥å®˜æ–¹æ–‡æ¡£è·å–æœ€æ–°ç«¯ç‚¹
   # æ›´æ–°settings.py
   nano_banana_base_url: str = "https://api-new.nanobananapro.com/v2"
   ```

---

#### é—®é¢˜2ï¼šVeo3è§†é¢‘ç”Ÿæˆè¶…æ—¶

**ç—‡çŠ¶ï¼š**
```
TimeoutError: Video generation timeout after 600s
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# è°ƒæ•´è¶…æ—¶é…ç½®
class Veo3Service:
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)

        # å¢åŠ è¶…æ—¶æ—¶é—´
        self.client = httpx.AsyncClient(
            base_url=self.base_url,
            headers={...},
            timeout=httpx.Timeout(
                connect=30.0,   # è¿æ¥è¶…æ—¶
                read=300.0,     # è¯»å–è¶…æ—¶
                write=30.0,     # å†™å…¥è¶…æ—¶
                pool=60.0       # è¿æ¥æ± è¶…æ—¶
            )
        )

    async def _wait_for_completion(self, task_id: str):
        # å¢åŠ æœ€å¤§ç­‰å¾…æ—¶é—´
        max_wait_time = 1200.0  # 20åˆ†é’Ÿ

        # åŠ¨æ€è°ƒæ•´è½®è¯¢é—´éš”
        poll_interval = 5.0
        max_poll_interval = 30.0

        elapsed = 0
        while elapsed < max_wait_time:
            status = await self.check_task_status(task_id)

            if status['state'] == 'completed':
                return status

            # æŒ‡æ•°å¢é•¿è½®è¯¢é—´éš”
            poll_interval = min(poll_interval * 1.2, max_poll_interval)
            await asyncio.sleep(poll_interval)
            elapsed += poll_interval

        raise TimeoutError(f"Timeout after {max_wait_time}s")
```

---

#### é—®é¢˜3ï¼šAPIé…é¢ä¸è¶³

**æ£€æµ‹ä¸å¤„ç†ï¼š**

```python
class QuotaManager:
    """APIé…é¢ç®¡ç†å™¨"""

    def __init__(self):
        self.usage = {
            'nano_banana': {'used': 0, 'limit': 1000},
            'veo3': {'used': 0, 'limit': 100}
        }

    async def check_quota(self, service: str) -> bool:
        """æ£€æŸ¥é…é¢æ˜¯å¦å……è¶³"""
        if self.usage[service]['used'] >= self.usage[service]['limit']:
            print(f"âš ï¸ {service} quota exceeded!")
            print(f"Used: {self.usage[service]['used']}/{self.usage[service]['limit']}")
            return False
        return True

    def update_usage(self, service: str, amount: int = 1):
        """æ›´æ–°ä½¿ç”¨é‡"""
        self.usage[service]['used'] += amount

    async def fetch_quota_from_api(self, service: str):
        """ä»APIè·å–å®é™…é…é¢ä¿¡æ¯"""
        # è°ƒç”¨APIçš„é…é¢æŸ¥è¯¢æ¥å£
        # å®é™…å®ç°ä¾èµ–APIæä¾›çš„æ¥å£
        pass

# é›†æˆåˆ°Orchestrator
class QuotaAwareOrchestrator(DramaGenerationOrchestrator):
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.quota_manager = QuotaManager()

    async def execute(self, *args, **kwargs):
        # æ£€æŸ¥é…é¢
        if not await self.quota_manager.check_quota('nano_banana'):
            raise RuntimeError("Nano Banana quota exceeded")

        if not await self.quota_manager.check_quota('veo3'):
            raise RuntimeError("Veo3 quota exceeded")

        # ç»§ç»­æ‰§è¡Œ
        return await super().execute(*args, **kwargs)
```

---

### 1.2 è§†é¢‘å¤„ç†é—®é¢˜

#### é—®é¢˜4ï¼šè§†é¢‘åˆæˆå¤±è´¥

**ç—‡çŠ¶ï¼š**
```
OSError: [Errno 2] No such file or directory: 'ffmpeg'
```

**è§£å†³æ–¹æ¡ˆï¼š**

```python
# æ£€æŸ¥FFmpegå®‰è£…
import subprocess
import sys

def check_ffmpeg():
    """æ£€æŸ¥FFmpegæ˜¯å¦æ­£ç¡®å®‰è£…"""
    try:
        result = subprocess.run(
            ['ffmpeg', '-version'],
            capture_output=True,
            text=True,
            check=True
        )
        print("âœ… FFmpegå·²å®‰è£…")
        print(result.stdout.split('\n')[0])
        return True

    except FileNotFoundError:
        print("âŒ FFmpegæœªå®‰è£…æˆ–ä¸åœ¨PATHä¸­")
        print("\nå®‰è£…æ–¹æ³•ï¼š")

        if sys.platform == 'win32':
            print("Windows: choco install ffmpeg")
        elif sys.platform == 'darwin':
            print("macOS: brew install ffmpeg")
        else:
            print("Linux: sudo apt install ffmpeg")

        return False

    except subprocess.CalledProcessError as e:
        print(f"âŒ FFmpegæ‰§è¡Œé”™è¯¯: {e}")
        return False

if __name__ == "__main__":
    check_ffmpeg()
```

**æŒ‡å®šFFmpegè·¯å¾„ï¼š**

```python
# å¦‚æœFFmpegä¸åœ¨PATHä¸­ï¼Œå¯ä»¥æ‰‹åŠ¨æŒ‡å®šè·¯å¾„
import os
os.environ["IMAGEIO_FFMPEG_EXE"] = "/path/to/ffmpeg"

# æˆ–åœ¨MoviePyä¸­æŒ‡å®š
from moviepy.config import change_settings
change_settings({"FFMPEG_BINARY": "/path/to/ffmpeg"})
```

---

#### é—®é¢˜5ï¼šéŸ³è§†é¢‘ä¸åŒæ­¥

**åŸå› åˆ†æï¼š**
- è§†é¢‘å¸§ç‡ä¸ä¸€è‡´
- éŸ³é¢‘é‡‡æ ·ç‡ä¸åŒ¹é…
- è½¬åœºæ•ˆæœå¯¼è‡´æ—¶é•¿å˜åŒ–

**è§£å†³æ–¹æ¡ˆï¼š**

```python
class SyncedVideoComposer(VideoComposerAgent):
    """éŸ³è§†é¢‘åŒæ­¥çš„åˆæˆå™¨"""

    def _normalize_clips(self, clips: List[VideoFileClip]) -> List[VideoFileClip]:
        """
        æ ‡å‡†åŒ–æ‰€æœ‰è§†é¢‘ç‰‡æ®µçš„å‚æ•°

        Args:
            clips: åŸå§‹è§†é¢‘ç‰‡æ®µåˆ—è¡¨

        Returns:
            æ ‡å‡†åŒ–åçš„ç‰‡æ®µåˆ—è¡¨
        """
        target_fps = self.config.get('fps', 30)
        target_audio_fps = 44100

        normalized = []

        for clip in clips:
            # ç»Ÿä¸€å¸§ç‡
            if clip.fps != target_fps:
                clip = clip.set_fps(target_fps)

            # ç»Ÿä¸€éŸ³é¢‘é‡‡æ ·ç‡
            if clip.audio:
                clip.audio = clip.audio.set_fps(target_audio_fps)

            normalized.append(clip)

        return normalized

    async def execute(self, video_results, *args, **kwargs):
        """é‡å†™executeï¼Œæ·»åŠ æ ‡å‡†åŒ–æ­¥éª¤"""
        clips = self._load_video_clips(video_results)

        # æ ‡å‡†åŒ–ç‰‡æ®µ
        clips = self._normalize_clips(clips)

        # ç»§ç»­åˆæˆæµç¨‹
        # ...
```

---

#### é—®é¢˜6ï¼šè¾“å‡ºè§†é¢‘è´¨é‡å·®

**ä¼˜åŒ–ç¼–ç å‚æ•°ï¼š**

```python
class HighQualityVideoComposer(VideoComposerAgent):
    """é«˜è´¨é‡è§†é¢‘åˆæˆå™¨"""

    async def execute(self, video_results, output_filename, **kwargs):
        # ... å‰é¢çš„å¤„ç† ...

        # ä½¿ç”¨é«˜è´¨é‡ç¼–ç å‚æ•°
        final_clip.write_videofile(
            str(output_path),
            codec='libx264',
            audio_codec='aac',

            # è§†é¢‘è´¨é‡å‚æ•°
            bitrate='8000k',         # è§†é¢‘æ¯”ç‰¹ç‡
            preset='slow',           # ç¼–ç é¢„è®¾ï¼ˆslower=æ›´å¥½è´¨é‡ï¼‰
            ffmpeg_params=[
                '-crf', '18',        # è´¨é‡å› å­ï¼ˆ0-51ï¼Œè¶Šå°è¶Šå¥½ï¼‰
                '-pix_fmt', 'yuv420p',  # åƒç´ æ ¼å¼
                '-profile:v', 'high',   # H.264 profile
                '-level', '4.1'         # H.264 level
            ],

            # éŸ³é¢‘è´¨é‡å‚æ•°
            audio_bitrate='320k',    # éŸ³é¢‘æ¯”ç‰¹ç‡
            audio_fps=48000,         # éŸ³é¢‘é‡‡æ ·ç‡

            # å…¶ä»–å‚æ•°
            fps=self.config.get('fps', 30),
            threads=self.config.get('threads', 4),
            logger=None  # ç¦ç”¨MoviePyçš„è¿›åº¦æ¡
        )
```

**è´¨é‡å¯¹æ¯”è¡¨ï¼š**

| é¢„è®¾ | CRF | æ¯”ç‰¹ç‡ | æ–‡ä»¶å¤§å° | è´¨é‡ | ç¼–ç é€Ÿåº¦ |
|------|-----|--------|---------|------|----------|
| ultrafast | 23 | 4000k | å° | ä¸­ | æå¿« |
| fast | 20 | 6000k | ä¸­ | å¥½ | å¿« |
| medium | 18 | 8000k | ä¸­ | å¾ˆå¥½ | ä¸­ç­‰ |
| slow | 16 | 10000k | å¤§ | æå¥½ | æ…¢ |

---

### 1.3 æ€§èƒ½é—®é¢˜

#### é—®é¢˜7ï¼šç”Ÿæˆé€Ÿåº¦æ…¢

**æ€§èƒ½åˆ†æå·¥å…·ï¼š**

```python
import time
import asyncio
from functools import wraps

def async_timer(func):
    """å¼‚æ­¥å‡½æ•°è®¡æ—¶è£…é¥°å™¨"""
    @wraps(func)
    async def wrapper(*args, **kwargs):
        start = time.time()
        result = await func(*args, **kwargs)
        elapsed = time.time() - start

        print(f"â±ï¸ {func.__name__} took {elapsed:.2f}s")
        return result
    return wrapper

# ä½¿ç”¨
class ProfiledOrchestrator(DramaGenerationOrchestrator):
    @async_timer
    async def execute(self, *args, **kwargs):
        return await super().execute(*args, **kwargs)

    @async_timer
    async def _parse_script(self, *args, **kwargs):
        # ...
        pass
```

**æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š**

1. **å¢åŠ å¹¶å‘æ•°**ï¼ˆåœ¨APIé™åˆ¶å†…ï¼‰
   ```python
   config = {
       'image': {'max_concurrent': 5},  # ä»3å¢åŠ åˆ°5
       'video': {'max_concurrent': 3}   # ä»2å¢åŠ åˆ°3
   }
   ```

2. **ä½¿ç”¨ç¼“å­˜**
   ```python
   # å¯ç”¨ç»“æœç¼“å­˜
   orchestrator = CachedOrchestrator(
       config=config,
       enable_cache=True
   )
   ```

3. **é¢„å¤„ç†å‰§æœ¬**
   ```python
   # æå‰éªŒè¯å’Œä¼˜åŒ–å‰§æœ¬
   script = await parser.execute(script_text)

   # ç§»é™¤é‡å¤åœºæ™¯
   unique_scenes = remove_duplicate_scenes(script.scenes)

   # ä¼˜åŒ–åˆ†é•œè®¾è®¡
   optimized_scenes = optimize_storyboard(unique_scenes)
   ```

---

#### é—®é¢˜8ï¼šå†…å­˜å ç”¨è¿‡é«˜

**å†…å­˜ç›‘æ§ï¼š**

```python
import psutil
import gc

class MemoryEfficientOrchestrator(DramaGenerationOrchestrator):
    """å†…å­˜ä¼˜åŒ–çš„Orchestrator"""

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.memory_threshold = 80.0  # å†…å­˜ä½¿ç”¨é˜ˆå€¼ï¼ˆ%ï¼‰

    async def _check_memory(self):
        """æ£€æŸ¥å†…å­˜ä½¿ç”¨æƒ…å†µ"""
        memory = psutil.virtual_memory()
        if memory.percent > self.memory_threshold:
            print(f"âš ï¸ High memory usage: {memory.percent:.1f}%")
            # è§¦å‘åƒåœ¾å›æ”¶
            gc.collect()

    async def execute(self, *args, **kwargs):
        # åœ¨å…³é”®æ­¥éª¤åæ£€æŸ¥å†…å­˜
        script = await self.script_parser.execute(...)
        await self._check_memory()

        image_results = await self.image_generator.execute(...)
        await self._check_memory()

        # åŠæ—¶é‡Šæ”¾ä¸å†éœ€è¦çš„èµ„æº
        del script
        gc.collect()

        # ...
```

**å‡å°‘å†…å­˜å ç”¨çš„æŠ€å·§ï¼š**

1. **æµå¼å¤„ç†**
   ```python
   # ä¸è¦ä¸€æ¬¡åŠ è½½æ‰€æœ‰è§†é¢‘åˆ°å†…å­˜
   # æ”¹ä¸ºé€ä¸ªå¤„ç†
   for i, video_result in enumerate(video_results):
       clip = VideoFileClip(video_result['video_path'])
       # å¤„ç†clip
       clip.close()  # ç«‹å³é‡Šæ”¾
   ```

2. **ä½¿ç”¨ç”Ÿæˆå™¨**
   ```python
   def load_clips_generator(video_paths):
       """ä½¿ç”¨ç”Ÿæˆå™¨é€ä¸ªåŠ è½½clip"""
       for path in video_paths:
           clip = VideoFileClip(path)
           yield clip
           clip.close()
   ```

---

### 1.4 ç¯å¢ƒé…ç½®é—®é¢˜

#### é—®é¢˜9ï¼šä¾èµ–åŒ…å†²çª

**ç—‡çŠ¶ï¼š**
```
ERROR: pip's dependency resolver does not currently take into account...
```

**è§£å†³æ–¹æ¡ˆï¼š**

```bash
# åˆ›å»ºå¹²å‡€çš„è™šæ‹Ÿç¯å¢ƒ
python -m venv venv_clean
source venv_clean/bin/activate

# ä½¿ç”¨pip-toolsé”å®šä¾èµ–
pip install pip-tools

# åˆ›å»ºrequirements.inï¼ˆåªåˆ—å‡ºç›´æ¥ä¾èµ–ï¼‰
# requirements.in
python-dotenv
pydantic
httpx
aiohttp
moviepy
ffmpeg-python

# ç”Ÿæˆé”å®šçš„requirements.txt
pip-compile requirements.in

# å®‰è£…
pip install -r requirements.txt
```

**ç‰ˆæœ¬å…¼å®¹æ€§çŸ©é˜µï¼š**

| Python | MoviePy | FFmpeg-python | Pydantic |
|--------|---------|---------------|----------|
| 3.8 | 1.0.3 | 0.2.0 | 2.5.0 |
| 3.9 | 1.0.3 | 0.2.0 | 2.5.0 |
| 3.10 | 1.0.3 | 0.2.0 | 2.5.0 âœ… |
| 3.11 | 1.0.3 | 0.2.0 | 2.5.0 |

---

## 2. æµ‹è¯•ä¸è´¨é‡ä¿è¯

### 2.1 å•å…ƒæµ‹è¯•

åˆ›å»º`tests/test_agents/test_script_parser.py`ï¼š

```python
import pytest
import asyncio
from agents.script_parser_agent import ScriptParserAgent
from models.script_models import Script

@pytest.fixture
def sample_script():
    """æµ‹è¯•ç”¨å‰§æœ¬"""
    return """
# æµ‹è¯•å‰§æœ¬

## è§’è‰²
- å°æ˜: ç¨‹åºå‘˜

## åœºæ™¯1ï¼šåŠå…¬å®¤
åœ°ç‚¹: åŠå…¬å®¤
æ—¶é—´: ç™½å¤©
æè¿°: å°æ˜åœ¨å·¥ä½œ
æ—¶é•¿: 3.0

å°æ˜ï¼ˆä¸“æ³¨ï¼‰ï¼šä»£ç å†™å®Œäº†ï¼
    """

@pytest.mark.asyncio
async def test_script_parser_basic(sample_script):
    """æµ‹è¯•åŸºç¡€å‰§æœ¬è§£æ"""
    parser = ScriptParserAgent()
    script = await parser.execute(sample_script)

    assert isinstance(script, Script)
    assert script.title == "æµ‹è¯•å‰§æœ¬"
    assert len(script.characters) == 1
    assert script.characters[0].name == "å°æ˜"
    assert len(script.scenes) == 1
    assert script.scenes[0].location == "åŠå…¬å®¤"

@pytest.mark.asyncio
async def test_script_parser_invalid_input():
    """æµ‹è¯•æ— æ•ˆè¾“å…¥"""
    parser = ScriptParserAgent()

    with pytest.raises(ValueError):
        await parser.execute("")

@pytest.mark.asyncio
async def test_scene_to_prompt():
    """æµ‹è¯•åœºæ™¯è½¬æç¤ºè¯"""
    parser = ScriptParserAgent()
    script = await parser.execute(sample_script)

    prompt = script.scenes[0].to_image_prompt()

    assert "åŠå…¬å®¤" in prompt
    assert "ç™½å¤©" in prompt
    assert "å°æ˜åœ¨å·¥ä½œ" in prompt

# è¿è¡Œæµ‹è¯•
# pytest tests/test_agents/test_script_parser.py -v
```

---

### 2.2 é›†æˆæµ‹è¯•

åˆ›å»º`tests/test_integration/test_full_workflow.py`ï¼š

```python
import pytest
import asyncio
from pathlib import Path
from agents.orchestrator_agent import DramaGenerationOrchestrator

@pytest.fixture
def test_config():
    """æµ‹è¯•é…ç½®"""
    return {
        'image': {
            'max_concurrent': 2,
            'image_width': 512,
            'image_height': 288,
            'quality': 'low'
        },
        'video': {
            'max_concurrent': 1,
            'resolution': '1280x720'
        }
    }

@pytest.fixture
def test_script():
    """æµ‹è¯•å‰§æœ¬"""
    return """
# é›†æˆæµ‹è¯•å‰§æœ¬

## è§’è‰²
- æµ‹è¯•è§’è‰²: ç”¨äºæµ‹è¯•

## åœºæ™¯1ï¼šæµ‹è¯•åœºæ™¯
åœ°ç‚¹: æµ‹è¯•ç¯å¢ƒ
æ—¶é—´: ç°åœ¨
æè¿°: è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•åœºæ™¯
æ—¶é•¿: 2.0
    """

@pytest.mark.asyncio
@pytest.mark.slow  # æ ‡è®°ä¸ºæ…¢é€Ÿæµ‹è¯•
async def test_full_generation_workflow(test_config, test_script):
    """æµ‹è¯•å®Œæ•´ç”Ÿæˆæµç¨‹"""

    orchestrator = DramaGenerationOrchestrator(config=test_config)

    try:
        video_path = await orchestrator.execute(
            script_text=test_script,
            output_filename="test_output.mp4"
        )

        # éªŒè¯è¾“å‡º
        assert Path(video_path).exists()
        assert Path(video_path).stat().st_size > 0

        # éªŒè¯è§†é¢‘å±æ€§
        from utils.video_utils import FFmpegProcessor
        ffmpeg = FFmpegProcessor()
        info = ffmpeg.get_video_info(video_path)

        assert info['width'] == 1280
        assert info['height'] == 720
        assert info['duration'] > 0

    finally:
        await orchestrator.close()

        # æ¸…ç†æµ‹è¯•æ–‡ä»¶
        if Path("test_output.mp4").exists():
            Path("test_output.mp4").unlink()

# è¿è¡Œé›†æˆæµ‹è¯•
# pytest tests/test_integration/ -v -m slow
```

---

### 2.3 æ€§èƒ½æµ‹è¯•

åˆ›å»º`tests/test_performance/test_benchmarks.py`ï¼š

```python
import pytest
import asyncio
import time
from agents.image_generator_agent import ImageGenerationAgent

@pytest.mark.benchmark
@pytest.mark.asyncio
async def test_image_generation_performance():
    """æµ‹è¯•å›¾ç‰‡ç”Ÿæˆæ€§èƒ½"""

    generator = ImageGenerationAgent(config={
        'max_concurrent': 3
    })

    # åˆ›å»ºæµ‹è¯•åœºæ™¯
    from models.script_models import Scene
    scenes = [
        Scene(
            scene_id=f"perf_test_{i}",
            location="test",
            time="day",
            description=f"Performance test scene {i}",
            duration=3.0
        )
        for i in range(10)
    ]

    # æµ‹è¯•
    start = time.time()
    results = await generator.execute_concurrent(scenes)
    elapsed = time.time() - start

    # æ–­è¨€
    assert len(results) == 10
    assert elapsed < 60.0  # åº”åœ¨60ç§’å†…å®Œæˆ

    # æ‰“å°æ€§èƒ½æŒ‡æ ‡
    avg_time = elapsed / len(scenes)
    print(f"\næ€§èƒ½æŒ‡æ ‡:")
    print(f"  æ€»è€—æ—¶: {elapsed:.2f}s")
    print(f"  å¹³å‡æ¯ä¸ªåœºæ™¯: {avg_time:.2f}s")
    print(f"  ååé‡: {len(scenes) / elapsed:.2f} scenes/s")

# è¿è¡Œæ€§èƒ½æµ‹è¯•
# pytest tests/test_performance/ -v -m benchmark -s
```

---

## 3. é¡¹ç›®éƒ¨ç½²

### 3.1 æœ¬åœ°éƒ¨ç½²

åˆ›å»º`scripts/setup.sh`ï¼š

```bash
#!/bin/bash
# æœ¬åœ°ç¯å¢ƒsetupè„šæœ¬

echo "ğŸš€ Setting up AI Drama Generator..."

# æ£€æŸ¥Pythonç‰ˆæœ¬
python_version=$(python3 --version 2>&1 | grep -oP '\d+\.\d+')
required_version="3.8"

if (( $(echo "$python_version < $required_version" | bc -l) )); then
    echo "âŒ Python $required_version or higher is required"
    exit 1
fi

echo "âœ… Python $python_version detected"

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
echo "ğŸ“¦ Creating virtual environment..."
python3 -m venv venv

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source venv/bin/activate

# å‡çº§pip
pip install --upgrade pip

# å®‰è£…ä¾èµ–
echo "ğŸ“¥ Installing dependencies..."
pip install -r requirements.txt

# æ£€æŸ¥FFmpeg
if ! command -v ffmpeg &> /dev/null; then
    echo "âš ï¸ FFmpeg not found"
    echo "Please install FFmpeg:"
    echo "  macOS: brew install ffmpeg"
    echo "  Ubuntu: sudo apt install ffmpeg"
    exit 1
fi

echo "âœ… FFmpeg detected"

# åˆ›å»ºå¿…è¦ç›®å½•
echo "ğŸ“ Creating directories..."
mkdir -p output/{images,videos,final}
mkdir -p temp
mkdir -p logs
mkdir -p checkpoints
mkdir -p cache

# å¤åˆ¶é…ç½®æ–‡ä»¶æ¨¡æ¿
if [ ! -f .env ]; then
    echo "ğŸ“ Creating .env file..."
    cp .env.example .env
    echo "âš ï¸ Please edit .env file and add your API keys"
fi

echo "âœ… Setup completed!"
echo ""
echo "Next steps:"
echo "1. Edit .env file and add your API keys"
echo "2. Activate virtual environment: source venv/bin/activate"
echo "3. Run example: python examples/quick_start.py"
```

---

### 3.2 Dockeréƒ¨ç½²

åˆ›å»º`Dockerfile`ï¼š

```dockerfile
# ä½¿ç”¨Pythonå®˜æ–¹é•œåƒ
FROM python:3.10-slim

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å®‰è£…ç³»ç»Ÿä¾èµ–
RUN apt-get update && apt-get install -y \
    ffmpeg \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# å¤åˆ¶requirements
COPY requirements.txt .

# å®‰è£…Pythonä¾èµ–
RUN pip install --no-cache-dir -r requirements.txt

# å¤åˆ¶é¡¹ç›®æ–‡ä»¶
COPY . .

# åˆ›å»ºå¿…è¦ç›®å½•
RUN mkdir -p output temp logs checkpoints cache

# æš´éœ²ç«¯å£ï¼ˆå¦‚æœæœ‰Webç•Œé¢ï¼‰
EXPOSE 8000

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV PYTHONUNBUFFERED=1

# é»˜è®¤å‘½ä»¤
CMD ["python", "main.py"]
```

åˆ›å»º`docker-compose.yml`ï¼š

```yaml
version: '3.8'

services:
  ai-drama-generator:
    build: .
    container_name: drama-generator
    volumes:
      - ./output:/app/output
      - ./temp:/app/temp
      - ./logs:/app/logs
      - ./cache:/app/cache
      - ./.env:/app/.env
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    # å¦‚æœéœ€è¦GPUæ”¯æŒ
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

# å¯é€‰ï¼šæ·»åŠ Redisç”¨äºç¼“å­˜
  redis:
    image: redis:7-alpine
    container_name: drama-cache
    ports:
      - "6379:6379"
    volumes:
      - redis-data:/data

volumes:
  redis-data:
```

**ä½¿ç”¨Dockeréƒ¨ç½²ï¼š**

```bash
# æ„å»ºé•œåƒ
docker-compose build

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

---

### 3.3 äº‘æœåŠ¡å™¨éƒ¨ç½²

#### AWS EC2éƒ¨ç½²ç¤ºä¾‹

åˆ›å»º`scripts/deploy_aws.sh`ï¼š

```bash
#!/bin/bash
# AWS EC2éƒ¨ç½²è„šæœ¬

SERVER_IP="your-ec2-ip"
KEY_FILE="~/.ssh/your-key.pem"
PROJECT_DIR="/home/ubuntu/ai-drama-generator"

echo "ğŸš€ Deploying to AWS EC2: $SERVER_IP"

# 1. ä¸Šä¼ ä»£ç 
echo "ğŸ“¤ Uploading code..."
rsync -avz -e "ssh -i $KEY_FILE" \
    --exclude 'venv' \
    --exclude '__pycache__' \
    --exclude '.git' \
    --exclude 'output' \
    --exclude 'temp' \
    ./ ubuntu@$SERVER_IP:$PROJECT_DIR/

# 2. SSHåˆ°æœåŠ¡å™¨å¹¶æ‰§è¡Œsetup
ssh -i $KEY_FILE ubuntu@$SERVER_IP << 'EOF'
cd /home/ubuntu/ai-drama-generator

# å®‰è£…ç³»ç»Ÿä¾èµ–
sudo apt-get update
sudo apt-get install -y python3-pip python3-venv ffmpeg

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt

# åˆ›å»ºsystemdæœåŠ¡
sudo tee /etc/systemd/system/drama-generator.service > /dev/null <<SERVICE
[Unit]
Description=AI Drama Generator
After=network.target

[Service]
Type=simple
User=ubuntu
WorkingDirectory=/home/ubuntu/ai-drama-generator
Environment="PATH=/home/ubuntu/ai-drama-generator/venv/bin"
ExecStart=/home/ubuntu/ai-drama-generator/venv/bin/python main.py
Restart=always

[Install]
WantedBy=multi-user.target
SERVICE

# å¯åŠ¨æœåŠ¡
sudo systemctl daemon-reload
sudo systemctl enable drama-generator
sudo systemctl start drama-generator

echo "âœ… Deployment completed!"
EOF
```

---

## 4. ç”Ÿäº§ç¯å¢ƒä¼˜åŒ–

### 4.1 å®‰å…¨æ€§åŠ å›º

åˆ›å»º`security/secrets_manager.py`ï¼š

```python
import os
from typing import Optional
from cryptography.fernet import Fernet
import json

class SecretsManager:
    """å®‰å…¨çš„å¯†é’¥ç®¡ç†å™¨"""

    def __init__(self, key: Optional[bytes] = None):
        """
        åˆå§‹åŒ–å¯†é’¥ç®¡ç†å™¨

        Args:
            key: åŠ å¯†å¯†é’¥ï¼ˆå¦‚æœä¸ºNoneï¼Œä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
        """
        if key is None:
            key = os.environ.get('SECRET_KEY', '').encode()
            if not key:
                # ç”Ÿæˆæ–°å¯†é’¥
                key = Fernet.generate_key()
                print(f"âš ï¸ Generated new secret key: {key.decode()}")
                print("âš ï¸ Please save this key in SECRET_KEY environment variable")

        self.cipher = Fernet(key)

    def encrypt(self, data: str) -> str:
        """åŠ å¯†æ•°æ®"""
        return self.cipher.encrypt(data.encode()).decode()

    def decrypt(self, encrypted_data: str) -> str:
        """è§£å¯†æ•°æ®"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()

    def save_secrets(self, secrets: dict, file_path: str):
        """ä¿å­˜åŠ å¯†çš„secrets"""
        encrypted = {
            k: self.encrypt(v) if isinstance(v, str) else v
            for k, v in secrets.items()
        }

        with open(file_path, 'w') as f:
            json.dump(encrypted, f)

    def load_secrets(self, file_path: str) -> dict:
        """åŠ è½½å¹¶è§£å¯†secrets"""
        with open(file_path, 'r') as f:
            encrypted = json.load(f)

        return {
            k: self.decrypt(v) if isinstance(v, str) else v
            for k, v in encrypted.items()
        }

# ä½¿ç”¨
secrets_manager = SecretsManager()

# ä¿å­˜APIå¯†é’¥
secrets_manager.save_secrets({
    'nano_banana_api_key': 'your_key_here',
    'veo3_api_key': 'your_key_here'
}, 'secrets.enc')

# åŠ è½½APIå¯†é’¥
secrets = secrets_manager.load_secrets('secrets.enc')
```

**å®‰å…¨æ£€æŸ¥æ¸…å•ï¼š**

- [ ] APIå¯†é’¥ä¸ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
- [ ] ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–åŠ å¯†æ–‡ä»¶å­˜å‚¨æ•æ„Ÿä¿¡æ¯
- [ ] .envæ–‡ä»¶æ·»åŠ åˆ°.gitignore
- [ ] å®šæœŸè½®æ¢APIå¯†é’¥
- [ ] ä½¿ç”¨HTTPSä¼ è¾“æ•°æ®
- [ ] å®æ–½è®¿é—®æ§åˆ¶å’Œæƒé™ç®¡ç†

---

### 4.2 ç›‘æ§ä¸å‘Šè­¦

åˆ›å»º`monitoring/metrics.py`ï¼š

```python
import time
import psutil
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, Any
import json

@dataclass
class Metrics:
    """ç³»ç»ŸæŒ‡æ ‡"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    disk_usage_percent: float
    active_tasks: int
    completed_tasks: int
    failed_tasks: int
    avg_task_duration: float

class MetricsCollector:
    """æŒ‡æ ‡æ”¶é›†å™¨"""

    def __init__(self):
        self.metrics_history = []
        self.task_durations = []
        self.task_counts = {
            'active': 0,
            'completed': 0,
            'failed': 0
        }

    def collect_system_metrics(self) -> Metrics:
        """æ”¶é›†ç³»ç»ŸæŒ‡æ ‡"""
        cpu = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory().percent
        disk = psutil.disk_usage('/').percent

        avg_duration = (
            sum(self.task_durations) / len(self.task_durations)
            if self.task_durations else 0
        )

        metrics = Metrics(
            timestamp=datetime.now(),
            cpu_percent=cpu,
            memory_percent=memory,
            disk_usage_percent=disk,
            active_tasks=self.task_counts['active'],
            completed_tasks=self.task_counts['completed'],
            failed_tasks=self.task_counts['failed'],
            avg_task_duration=avg_duration
        )

        self.metrics_history.append(metrics)
        return metrics

    def record_task_completion(self, duration: float, success: bool):
        """è®°å½•ä»»åŠ¡å®Œæˆ"""
        self.task_durations.append(duration)
        self.task_counts['active'] -= 1

        if success:
            self.task_counts['completed'] += 1
        else:
            self.task_counts['failed'] += 1

    def export_metrics(self, file_path: str):
        """å¯¼å‡ºæŒ‡æ ‡åˆ°æ–‡ä»¶"""
        data = [
            {
                'timestamp': m.timestamp.isoformat(),
                'cpu': m.cpu_percent,
                'memory': m.memory_percent,
                'disk': m.disk_usage_percent,
                'tasks': {
                    'active': m.active_tasks,
                    'completed': m.completed_tasks,
                    'failed': m.failed_tasks
                }
            }
            for m in self.metrics_history
        ]

        with open(file_path, 'w') as f:
            json.dump(data, f, indent=2)

# å‘Šè­¦ç³»ç»Ÿ
class AlertSystem:
    """å‘Šè­¦ç³»ç»Ÿ"""

    def __init__(self, metrics_collector: MetricsCollector):
        self.metrics = metrics_collector
        self.alert_thresholds = {
            'cpu': 90.0,
            'memory': 85.0,
            'disk': 90.0,
            'error_rate': 0.1  # 10% é”™è¯¯ç‡
        }

    def check_alerts(self) -> list[str]:
        """æ£€æŸ¥æ˜¯å¦éœ€è¦å‘Šè­¦"""
        alerts = []
        latest = self.metrics.collect_system_metrics()

        if latest.cpu_percent > self.alert_thresholds['cpu']:
            alerts.append(f"ğŸš¨ High CPU: {latest.cpu_percent:.1f}%")

        if latest.memory_percent > self.alert_thresholds['memory']:
            alerts.append(f"ğŸš¨ High Memory: {latest.memory_percent:.1f}%")

        if latest.disk_usage_percent > self.alert_thresholds['disk']:
            alerts.append(f"ğŸš¨ Low Disk Space: {latest.disk_usage_percent:.1f}%")

        total = latest.completed_tasks + latest.failed_tasks
        if total > 0:
            error_rate = latest.failed_tasks / total
            if error_rate > self.alert_thresholds['error_rate']:
                alerts.append(f"ğŸš¨ High Error Rate: {error_rate*100:.1f}%")

        return alerts

# ä½¿ç”¨
collector = MetricsCollector()
alert_system = AlertSystem(collector)

# å®šæœŸæ£€æŸ¥
import asyncio

async def monitor_loop():
    while True:
        alerts = alert_system.check_alerts()
        for alert in alerts:
            print(alert)
            # å‘é€åˆ°Slack/é‚®ä»¶/ç­‰

        await asyncio.sleep(60)  # æ¯åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡
```

---

### 4.3 æ‰©å±•æ€§è®¾è®¡

#### æ’ä»¶ç³»ç»Ÿ

åˆ›å»º`plugins/plugin_system.py`ï¼š

```python
from typing import Dict, Any, Callable
from abc import ABC, abstractmethod

class Plugin(ABC):
    """æ’ä»¶åŸºç±»"""

    @abstractmethod
    def initialize(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–æ’ä»¶"""
        pass

    @abstractmethod
    async def execute(self, *args, **kwargs) -> Any:
        """æ‰§è¡Œæ’ä»¶åŠŸèƒ½"""
        pass

class PluginManager:
    """æ’ä»¶ç®¡ç†å™¨"""

    def __init__(self):
        self.plugins: Dict[str, Plugin] = {}
        self.hooks: Dict[str, list[Callable]] = {}

    def register_plugin(self, name: str, plugin: Plugin):
        """æ³¨å†Œæ’ä»¶"""
        self.plugins[name] = plugin

    def register_hook(self, hook_name: str, callback: Callable):
        """æ³¨å†Œé’©å­"""
        if hook_name not in self.hooks:
            self.hooks[hook_name] = []
        self.hooks[hook_name].append(callback)

    async def trigger_hook(self, hook_name: str, *args, **kwargs):
        """è§¦å‘é’©å­"""
        if hook_name in self.hooks:
            for callback in self.hooks[hook_name]:
                await callback(*args, **kwargs)

# ç¤ºä¾‹æ’ä»¶ï¼šè‡ªå®šä¹‰å›¾ç‰‡é£æ ¼
class CustomStylePlugin(Plugin):
    """è‡ªå®šä¹‰é£æ ¼æ’ä»¶"""

    def initialize(self, config: Dict[str, Any]):
        self.style_presets = config.get('style_presets', {})

    async def execute(self, prompt: str, style: str) -> str:
        """åº”ç”¨è‡ªå®šä¹‰é£æ ¼"""
        if style in self.style_presets:
            style_suffix = self.style_presets[style]
            return f"{prompt}, {style_suffix}"
        return prompt

# ä½¿ç”¨æ’ä»¶
plugin_manager = PluginManager()

# æ³¨å†Œæ’ä»¶
custom_style = CustomStylePlugin()
custom_style.initialize({
    'style_presets': {
        'anime': 'anime style, vibrant colors',
        'realistic': 'photorealistic, high detail'
    }
})

plugin_manager.register_plugin('custom_style', custom_style)

# åœ¨ç”Ÿæˆæµç¨‹ä¸­ä½¿ç”¨
async def generate_with_plugins(prompt, style):
    plugin = plugin_manager.plugins['custom_style']
    enhanced_prompt = await plugin.execute(prompt, style)
    # ç»§ç»­ç”Ÿæˆ...
```

---

## 5. é™„å½•

### 5.1 å®Œæ•´é¡¹ç›®ç¤ºä¾‹

GitHubä»“åº“ç»“æ„ï¼š

```
ai-drama-generator/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml              # GitHub Actions CI/CD
â”œâ”€â”€ agents/
â”œâ”€â”€ services/
â”œâ”€â”€ utils/
â”œâ”€â”€ config/
â”œâ”€â”€ models/
â”œâ”€â”€ tests/
â”œâ”€â”€ examples/
â”œâ”€â”€ scripts/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ API.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md
â”‚   â””â”€â”€ CONTRIBUTING.md
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---

### 5.2 APIæ–‡æ¡£å‚è€ƒ

**Nano Banana Pro API**ï¼ˆç¤ºä¾‹ï¼‰
```
å®˜æ–¹æ–‡æ¡£: https://docs.nanobananapro.com
ç«¯ç‚¹: POST /v1/generate-image
è®¤è¯: Bearer Token
```

**Veo3 API**ï¼ˆç¤ºä¾‹ï¼‰
```
å®˜æ–¹æ–‡æ¡£: https://docs.veo3.ai
ç«¯ç‚¹: POST /v1/image-to-video
è®¤è¯: API Key Header
```

---

### 5.3 æ‰©å±•é˜…è¯»

**ç›¸å…³æŠ€æœ¯èµ„æºï¼š**

1. **AIå›¾ç‰‡ç”Ÿæˆ**
   - Stable Diffusionæ–‡æ¡£
   - DALL-E APIæŒ‡å—
   - Midjourney Prompt Engineering

2. **è§†é¢‘å¤„ç†**
   - FFmpegå®˜æ–¹æ–‡æ¡£
   - MoviePyæ•™ç¨‹
   - OpenCVè§†é¢‘å¤„ç†

3. **Agentæ¶æ„**
   - LangChainæ–‡æ¡£
   - AutoGenè®ºæ–‡
   - Multi-Agent Systems

4. **å¼‚æ­¥ç¼–ç¨‹**
   - Python asyncioå®˜æ–¹æ–‡æ¡£
   - aiohttpæœ€ä½³å®è·µ

**ç¤¾åŒºèµ„æºï¼š**
- GitHub: awesome-ai-video
- Discord: AI Video Generation Community
- Reddit: r/aiVideoGeneration

---

## ç»“è¯­

æ­å–œä½ å®Œæˆäº†ã€ŠAIçŸ­å‰§è‡ªåŠ¨åŒ–ç”Ÿæˆç³»ç»Ÿã€‹çš„å®Œæ•´æ•™ç¨‹ï¼

ä½ ç°åœ¨å·²ç»æŒæ¡äº†ï¼š
âœ… ç³»ç»Ÿæ¶æ„è®¾è®¡ä¸Agentåä½œæœºåˆ¶
âœ… å®Œæ•´çš„ä»£ç å®ç°ï¼ˆå‰§æœ¬è§£æã€å›¾ç‰‡/è§†é¢‘ç”Ÿæˆã€åˆæˆï¼‰
âœ… ç”Ÿäº§çº§åˆ«çš„æ€§èƒ½ä¼˜åŒ–å’Œé”™è¯¯å¤„ç†
âœ… éƒ¨ç½²å’Œè¿ç»´æœ€ä½³å®è·µ

**ä¸‹ä¸€æ­¥å»ºè®®ï¼š**
1. ä»ç¤ºä¾‹ä»£ç å¼€å§‹ï¼Œæ„å»ºè‡ªå·±çš„ç¬¬ä¸€ä¸ªçŸ­å‰§
2. æ ¹æ®å®é™…éœ€æ±‚å®šåˆ¶Agentè¡Œä¸º
3. é›†æˆæ›´å¤šAIæœåŠ¡ï¼ˆTTSã€å­—å¹•ç”Ÿæˆç­‰ï¼‰
4. åˆ†äº«ä½ çš„ä½œå“å’Œæ”¹è¿›å»ºè®®

**è·å–å¸®åŠ©ï¼š**
- æäº¤Issueåˆ°GitHubä»“åº“
- åŠ å…¥å¼€å‘è€…ç¤¾åŒºè®¨è®º
- æŸ¥é˜…æœ€æ–°APIæ–‡æ¡£

ç¥ä½ æ„å»ºå‡ºç²¾å½©çš„AIçŸ­å‰§ç”Ÿæˆç³»ç»Ÿï¼ğŸ¬âœ¨
