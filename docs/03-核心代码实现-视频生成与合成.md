# AI短剧自动化生成系统开发教程（第3部分）
## 核心代码实现：视频生成与合成

---

## 目录

1. [模块3：Veo3视频生成Agent](#模块3veo3视频生成agent)
   - 3.1 [Veo3 API服务封装](#31-veo3-api服务封装)
   - 3.2 [视频生成Agent实现](#32-视频生成agent实现)
   - 3.3 [异步任务管理](#33-异步任务管理)
2. [模块4：视频合成与后期处理](#模块4视频合成与后期处理)
   - 4.1 [FFmpeg视频处理工具](#41-ffmpeg视频处理工具)
   - 4.2 [MoviePy视频合成](#42-moviepy视频合成)
   - 4.3 [后期特效处理](#43-后期特效处理)
3. [模块5：主控Agent协调器](#模块5主控agent协调器)
   - 5.1 [工作流编排](#51-工作流编排)
   - 5.2 [状态管理与断点续传](#52-状态管理与断点续传)
   - 5.3 [进度监控与回调](#53-进度监控与回调)

---

## 模块3：Veo3视频生成Agent

### 3.1 Veo3 API服务封装

#### 3.1.1 Veo3服务客户端

创建`services/veo3_service.py`：

```python
import httpx
import asyncio
from typing import Dict, Any, Optional
from pathlib import Path
from config.settings import settings
from utils.retry import async_retry
import logging
import time

class Veo3Service:
    """Veo3 API服务封装 - 图片到视频转换"""

    def __init__(self, api_key: Optional[str] = None,
                 base_url: Optional[str] = None):
        """
        初始化服务

        Args:
            api_key: API密钥
            base_url: API基础URL
        """
        self.api_key = api_key or settings.veo3_api_key
        self.base_url = base_url or settings.veo3_base_url
        self.logger = logging.getLogger(__name__)

        self.client = httpx.AsyncClient(
            base_url=self.base_url,
            headers={
                "X-API-Key": self.api_key,
                "Content-Type": "application/json"
            },
            timeout=120.0  # Veo3生成视频可能较慢
        )

    async def close(self):
        """关闭客户端"""
        await self.client.aclose()

    @async_retry(max_attempts=3, backoff_factor=2.0)
    async def image_to_video(
        self,
        image_path: str,
        duration: float = 3.0,
        fps: int = 30,
        resolution: str = "1920x1080",
        motion_strength: float = 0.5,
        camera_motion: Optional[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        将图片转换为视频

        Args:
            image_path: 图片文件路径
            duration: 视频时长（秒）
            fps: 帧率
            resolution: 分辨率
            motion_strength: 运动强度（0.0-1.0）
            camera_motion: 摄像机运动类型（pan/tilt/zoom/static）
            **kwargs: 其他API参数

        Returns:
            API响应，包含任务ID或视频URL
        """
        # 读取并上传图片
        image_url = await self._upload_image(image_path)

        payload = {
            "image_url": image_url,
            "duration": duration,
            "fps": fps,
            "resolution": resolution,
            "motion_strength": motion_strength,
            "camera_motion": camera_motion or "static",
            **kwargs
        }

        self.logger.info(f"Initiating image-to-video conversion: {image_path}")

        try:
            response = await self.client.post(
                "/image-to-video",
                json=payload
            )
            response.raise_for_status()

            result = response.json()
            task_id = result.get('task_id')

            self.logger.info(f"Video generation task created: {task_id}")

            # 如果是异步任务，等待完成
            if task_id:
                result = await self._wait_for_completion(task_id)

            return result

        except httpx.HTTPStatusError as e:
            self.logger.error(f"Veo3 API request failed: {e.response.status_code}")
            self.logger.error(f"Response: {e.response.text}")
            raise

    async def _upload_image(self, image_path: str) -> str:
        """
        上传图片到Veo3服务器

        Args:
            image_path: 本地图片路径

        Returns:
            上传后的图片URL
        """
        with open(image_path, 'rb') as f:
            files = {'file': (Path(image_path).name, f, 'image/png')}

            # 注意：这里需要临时移除Content-Type header以支持multipart
            headers = {"X-API-Key": self.api_key}

            async with httpx.AsyncClient(base_url=self.base_url) as upload_client:
                response = await upload_client.post(
                    "/upload-image",
                    files=files,
                    headers=headers,
                    timeout=60.0
                )
                response.raise_for_status()

                result = response.json()
                image_url = result.get('url')

                self.logger.info(f"Image uploaded: {image_url}")
                return image_url

    async def _wait_for_completion(
        self,
        task_id: str,
        poll_interval: float = 5.0,
        max_wait_time: float = 600.0
    ) -> Dict[str, Any]:
        """
        等待视频生成任务完成

        Args:
            task_id: 任务ID
            poll_interval: 轮询间隔（秒）
            max_wait_time: 最大等待时间（秒）

        Returns:
            完成后的任务结果

        Raises:
            TimeoutError: 超过最大等待时间
        """
        start_time = time.time()

        while True:
            elapsed = time.time() - start_time
            if elapsed > max_wait_time:
                raise TimeoutError(
                    f"Video generation timeout after {max_wait_time}s"
                )

            # 查询任务状态
            status = await self.check_task_status(task_id)
            state = status.get('state')

            self.logger.info(
                f"Task {task_id} status: {state} "
                f"({elapsed:.1f}s elapsed)"
            )

            if state == 'completed':
                return status
            elif state == 'failed':
                error_msg = status.get('error', 'Unknown error')
                raise RuntimeError(f"Video generation failed: {error_msg}")

            await asyncio.sleep(poll_interval)

    async def check_task_status(self, task_id: str) -> Dict[str, Any]:
        """
        检查任务状态

        Args:
            task_id: 任务ID

        Returns:
            任务状态信息
        """
        response = await self.client.get(f"/task/{task_id}")
        response.raise_for_status()
        return response.json()

    async def download_video(self, video_url: str, save_path: Path) -> Path:
        """
        下载生成的视频

        Args:
            video_url: 视频URL
            save_path: 保存路径

        Returns:
            实际保存的文件路径
        """
        self.logger.info(f"Downloading video from {video_url}")

        try:
            async with httpx.AsyncClient() as download_client:
                response = await download_client.get(
                    video_url,
                    timeout=300.0,  # 视频文件可能较大
                    follow_redirects=True
                )
                response.raise_for_status()

                save_path.parent.mkdir(parents=True, exist_ok=True)

                with open(save_path, 'wb') as f:
                    f.write(response.content)

                self.logger.info(f"Video saved to {save_path}")
                return save_path

        except Exception as e:
            self.logger.error(f"Failed to download video: {e}")
            raise

    async def __aenter__(self):
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        await self.close()
```

---

### 3.2 视频生成Agent实现

创建`agents/video_generator_agent.py`：

```python
import asyncio
from typing import List, Dict, Any, Optional
from pathlib import Path
from agents.base_agent import BaseAgent
from services.veo3_service import Veo3Service
from models.script_models import Scene, CameraMovement
from utils.concurrency import ConcurrencyLimiter
import logging
from datetime import datetime

class VideoGenerationAgent(BaseAgent):
    """视频生成Agent - 将分镜图片转换为视频片段"""

    def __init__(
        self,
        agent_id: str = "video_generator",
        config: Dict[str, Any] = None,
        output_dir: Optional[Path] = None
    ):
        super().__init__(agent_id, config or {})
        self.output_dir = output_dir or Path("./output/videos")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.service = Veo3Service()
        self.logger = logging.getLogger(__name__)

        # 并发限制（Veo3生成较慢，建议降低并发数）
        max_concurrent = self.config.get('max_concurrent', 2)
        self.limiter = ConcurrencyLimiter(max_concurrent)

    async def execute(
        self,
        image_results: List[Dict[str, Any]],
        scenes: List[Scene]
    ) -> List[Dict[str, Any]]:
        """
        执行批量视频生成

        Args:
            image_results: 图片生成结果列表
            scenes: 对应的场景列表

        Returns:
            视频生成结果列表
        """
        if not await self.validate_input((image_results, scenes)):
            raise ValueError("Invalid input data")

        self.logger.info(f"Starting video generation for {len(image_results)} clips")

        try:
            # 构建任务列表
            tasks_data = []
            for img_result, scene in zip(image_results, scenes):
                tasks_data.append({
                    'image_result': img_result,
                    'scene': scene
                })

            # 并发执行
            results = await self.limiter.run_batch(
                self._generate_video_clip,
                tasks_data,
                show_progress=True
            )

            await self.on_complete(results)
            return results

        except Exception as e:
            await self.on_error(e)
            raise

    async def validate_input(self, input_data: tuple) -> bool:
        """验证输入数据"""
        image_results, scenes = input_data

        if not image_results or not scenes:
            return False

        if len(image_results) != len(scenes):
            self.logger.error("Image results and scenes count mismatch")
            return False

        return True

    async def _generate_video_clip(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        生成单个视频片段

        Args:
            task_data: 包含image_result和scene的字典

        Returns:
            视频生成结果
        """
        image_result = task_data['image_result']
        scene = task_data['scene']

        image_path = image_result['image_path']
        scene_id = scene.scene_id

        self.logger.info(f"Generating video for scene: {scene_id}")

        # 配置视频参数
        video_config = {
            'duration': scene.duration,
            'fps': self.config.get('fps', 30),
            'resolution': self.config.get('resolution', '1920x1080'),
            'motion_strength': self.config.get('motion_strength', 0.5),
            'camera_motion': self._map_camera_motion(scene.camera_movement)
        }

        # 调用Veo3 API生成视频
        api_result = await self.service.image_to_video(
            image_path=image_path,
            **video_config
        )

        # 下载视频
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"{scene_id}_{timestamp}.mp4"
        save_path = self.output_dir / filename

        video_path = await self.service.download_video(
            api_result['video_url'],
            save_path
        )

        return {
            'scene_id': scene_id,
            'video_path': str(video_path),
            'duration': scene.duration,
            'config': video_config,
            'api_response': api_result
        }

    def _map_camera_motion(self, movement: CameraMovement) -> str:
        """
        将Scene的camera_movement映射到Veo3的参数

        Args:
            movement: CameraMovement枚举

        Returns:
            Veo3 API支持的运动类型
        """
        motion_mapping = {
            CameraMovement.STATIC: 'static',
            CameraMovement.PAN: 'pan',
            CameraMovement.TILT: 'tilt',
            CameraMovement.ZOOM: 'zoom',
            CameraMovement.DOLLY: 'dolly',
            CameraMovement.TRACKING: 'tracking'
        }

        return motion_mapping.get(movement, 'static')

    async def close(self):
        """关闭资源"""
        await self.service.close()
```

---

### 3.3 异步任务管理

#### 3.3.1 任务队列管理器

创建`utils/task_queue.py`：

```python
import asyncio
from typing import Any, Callable, Dict, List, Optional
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import logging

class TaskStatus(Enum):
    """任务状态"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

@dataclass
class Task:
    """任务数据类"""
    task_id: str
    func: Callable
    args: tuple = field(default_factory=tuple)
    kwargs: Dict[str, Any] = field(default_factory=dict)
    status: TaskStatus = TaskStatus.PENDING
    result: Any = None
    error: Optional[Exception] = None
    created_at: datetime = field(default_factory=datetime.now)
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

class TaskQueue:
    """异步任务队列管理器"""

    def __init__(self, max_workers: int = 3):
        """
        初始化任务队列

        Args:
            max_workers: 最大并发worker数
        """
        self.max_workers = max_workers
        self.queue: asyncio.Queue[Task] = asyncio.Queue()
        self.tasks: Dict[str, Task] = {}
        self.workers: List[asyncio.Task] = []
        self.logger = logging.getLogger(__name__)
        self._running = False

    async def start(self):
        """启动worker"""
        if self._running:
            return

        self._running = True
        self.workers = [
            asyncio.create_task(self._worker(i))
            for i in range(self.max_workers)
        ]
        self.logger.info(f"Started {self.max_workers} workers")

    async def stop(self):
        """停止所有worker"""
        self._running = False

        # 等待队列清空
        await self.queue.join()

        # 取消所有worker
        for worker in self.workers:
            worker.cancel()

        await asyncio.gather(*self.workers, return_exceptions=True)
        self.logger.info("All workers stopped")

    async def submit(
        self,
        task_id: str,
        func: Callable,
        *args,
        **kwargs
    ) -> Task:
        """
        提交任务到队列

        Args:
            task_id: 任务ID
            func: 异步函数
            *args, **kwargs: 函数参数

        Returns:
            Task对象
        """
        task = Task(
            task_id=task_id,
            func=func,
            args=args,
            kwargs=kwargs
        )

        self.tasks[task_id] = task
        await self.queue.put(task)

        self.logger.info(f"Task submitted: {task_id}")
        return task

    async def get_result(
        self,
        task_id: str,
        timeout: Optional[float] = None
    ) -> Any:
        """
        获取任务结果（阻塞直到完成）

        Args:
            task_id: 任务ID
            timeout: 超时时间（秒）

        Returns:
            任务结果

        Raises:
            TimeoutError: 超时
            Exception: 任务执行失败
        """
        task = self.tasks.get(task_id)
        if not task:
            raise ValueError(f"Task not found: {task_id}")

        start_time = asyncio.get_event_loop().time()

        while task.status not in [TaskStatus.COMPLETED, TaskStatus.FAILED]:
            if timeout:
                elapsed = asyncio.get_event_loop().time() - start_time
                if elapsed > timeout:
                    raise TimeoutError(f"Task {task_id} timeout")

            await asyncio.sleep(0.1)

        if task.status == TaskStatus.FAILED:
            raise task.error

        return task.result

    async def _worker(self, worker_id: int):
        """Worker协程"""
        self.logger.info(f"Worker {worker_id} started")

        while self._running:
            try:
                # 从队列获取任务
                task = await asyncio.wait_for(
                    self.queue.get(),
                    timeout=1.0
                )

                # 执行任务
                await self._execute_task(task, worker_id)

                # 标记任务完成
                self.queue.task_done()

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                self.logger.error(f"Worker {worker_id} error: {e}")

        self.logger.info(f"Worker {worker_id} stopped")

    async def _execute_task(self, task: Task, worker_id: int):
        """执行单个任务"""
        task.status = TaskStatus.RUNNING
        task.started_at = datetime.now()

        self.logger.info(f"Worker {worker_id} executing task: {task.task_id}")

        try:
            result = await task.func(*task.args, **task.kwargs)
            task.result = result
            task.status = TaskStatus.COMPLETED
            task.completed_at = datetime.now()

            self.logger.info(f"Task completed: {task.task_id}")

        except Exception as e:
            task.error = e
            task.status = TaskStatus.FAILED
            task.completed_at = datetime.now()

            self.logger.error(f"Task failed: {task.task_id}, error: {e}")
```

---

## 模块4：视频合成与后期处理

### 4.1 FFmpeg视频处理工具

创建`utils/video_utils.py`：

```python
import ffmpeg
from pathlib import Path
from typing import List, Optional, Dict, Any
import logging
import subprocess

class FFmpegProcessor:
    """FFmpeg视频处理工具类"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def get_video_info(self, video_path: str) -> Dict[str, Any]:
        """
        获取视频信息

        Args:
            video_path: 视频文件路径

        Returns:
            视频元数据字典
        """
        try:
            probe = ffmpeg.probe(video_path)
            video_stream = next(
                (s for s in probe['streams'] if s['codec_type'] == 'video'),
                None
            )

            if not video_stream:
                raise ValueError("No video stream found")

            return {
                'duration': float(probe['format']['duration']),
                'width': int(video_stream['width']),
                'height': int(video_stream['height']),
                'fps': eval(video_stream['r_frame_rate']),
                'codec': video_stream['codec_name'],
                'bitrate': int(probe['format'].get('bit_rate', 0))
            }

        except ffmpeg.Error as e:
            self.logger.error(f"Failed to probe video: {e.stderr.decode()}")
            raise

    def convert_video(
        self,
        input_path: str,
        output_path: str,
        vcodec: str = 'libx264',
        acodec: str = 'aac',
        preset: str = 'medium',
        crf: int = 23
    ) -> str:
        """
        转换视频格式

        Args:
            input_path: 输入视频路径
            output_path: 输出视频路径
            vcodec: 视频编码器
            acodec: 音频编码器
            preset: 编码预设
            crf: 质量参数（0-51，越小质量越高）

        Returns:
            输出文件路径
        """
        try:
            stream = ffmpeg.input(input_path)
            stream = ffmpeg.output(
                stream,
                output_path,
                vcodec=vcodec,
                acodec=acodec,
                preset=preset,
                crf=crf
            )
            ffmpeg.run(stream, overwrite_output=True, quiet=True)

            self.logger.info(f"Video converted: {output_path}")
            return output_path

        except ffmpeg.Error as e:
            self.logger.error(f"Conversion failed: {e.stderr.decode()}")
            raise

    def resize_video(
        self,
        input_path: str,
        output_path: str,
        width: int,
        height: int
    ) -> str:
        """
        调整视频分辨率

        Args:
            input_path: 输入视频
            output_path: 输出视频
            width: 目标宽度
            height: 目标高度

        Returns:
            输出文件路径
        """
        try:
            stream = ffmpeg.input(input_path)
            stream = ffmpeg.filter(stream, 'scale', width, height)
            stream = ffmpeg.output(stream, output_path)
            ffmpeg.run(stream, overwrite_output=True, quiet=True)

            return output_path

        except ffmpeg.Error as e:
            self.logger.error(f"Resize failed: {e.stderr.decode()}")
            raise

    def add_audio(
        self,
        video_path: str,
        audio_path: str,
        output_path: str,
        audio_volume: float = 1.0
    ) -> str:
        """
        为视频添加音频

        Args:
            video_path: 视频文件
            audio_path: 音频文件
            output_path: 输出文件
            audio_volume: 音频音量（0.0-1.0）

        Returns:
            输出文件路径
        """
        try:
            video = ffmpeg.input(video_path)
            audio = ffmpeg.input(audio_path)

            # 调整音量
            if audio_volume != 1.0:
                audio = ffmpeg.filter(audio, 'volume', audio_volume)

            stream = ffmpeg.output(
                video,
                audio,
                output_path,
                vcodec='copy',
                acodec='aac',
                shortest=None
            )

            ffmpeg.run(stream, overwrite_output=True, quiet=True)
            return output_path

        except ffmpeg.Error as e:
            self.logger.error(f"Add audio failed: {e.stderr.decode()}")
            raise

    def concatenate_videos_filter(
        self,
        video_paths: List[str],
        output_path: str
    ) -> str:
        """
        使用filter方式拼接视频（适合需要转场效果的场景）

        Args:
            video_paths: 视频文件路径列表
            output_path: 输出文件路径

        Returns:
            输出文件路径
        """
        try:
            self.logger.info(f"Starting video concatenation for {len(video_paths)} videos")
            
            # 检测每个输入视频的音频流
            has_audio_streams = []
            for i, video_path in enumerate(video_paths):
                try:
                    probe = ffmpeg.probe(video_path)
                    has_audio = any(s['codec_type'] == 'audio' for s in probe['streams'])
                    has_audio_streams.append(has_audio)
                    self.logger.debug(f"Video {i+1}/{len(video_paths)} ({Path(video_path).name}): has_audio={has_audio}")
                    if not has_audio:
                        self.logger.warning(f"Video {i+1} has no audio stream: {video_path}")
                except Exception as e:
                    self.logger.warning(f"Failed to probe video {i+1}: {e}")
                    has_audio_streams.append(False)
            
            # 创建输入流并提取视频和音频流
            video_streams = []
            audio_streams = []
            
            for i, video_path in enumerate(video_paths):
                input_stream = ffmpeg.input(video_path)
                video_streams.append(input_stream.video)
                
                # 只有当视频有音频流时才添加
                if has_audio_streams[i]:
                    audio_streams.append(input_stream.audio)
                else:
                    # 为没有音频的视频创建静音音频流
                    silent_audio = ffmpeg.filter(
                        input_stream,
                        'anullsrc',
                        channel_layout='stereo',
                        sample_rate=44100
                    )
                    silent_audio = ffmpeg.filter(
                        [silent_audio, input_stream],
                        'atrim',
                        duration='shortest'
                    )
                    audio_streams.append(silent_audio)
            
            # 拼接所有视频流和音频流
            joined_video = ffmpeg.concat(*video_streams, v=1, a=0)
            joined_audio = ffmpeg.concat(*audio_streams, v=0, a=1)

            stream = ffmpeg.output(
                joined_video,
                joined_audio,
                output_path,
                vcodec='libx264',
                acodec='aac',
                preset='medium',
                audio_bitrate='192k'
            )

            ffmpeg.run(stream, overwrite_output=True, quiet=True)

            self.logger.info(f"Videos concatenated with audio successfully: {output_path}")
            return output_path

        except ffmpeg.Error as e:
            self.logger.error(f"Concatenation failed: {e.stderr.decode()}")
            raise
```

---

### 4.2 MoviePy视频合成

创建`agents/video_composer_agent.py`：

```python
from typing import List, Dict, Any, Optional
from pathlib import Path
from agents.base_agent import BaseAgent
from moviepy.editor import (
    VideoFileClip,
    concatenate_videoclips,
    CompositeVideoClip,
    AudioFileClip,
    TextClip
)
from utils.video_utils import FFmpegProcessor
import logging

class VideoComposerAgent(BaseAgent):
    """视频合成Agent - 将所有片段合成为完整短剧"""

    def __init__(
        self,
        agent_id: str = "video_composer",
        config: Dict[str, Any] = None,
        output_dir: Optional[Path] = None
    ):
        super().__init__(agent_id, config or {})
        self.output_dir = output_dir or Path("./output/final")
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.ffmpeg = FFmpegProcessor()
        self.logger = logging.getLogger(__name__)

    async def execute(
        self,
        video_results: List[Dict[str, Any]],
        output_filename: str = "final_drama.mp4",
        bgm_path: Optional[str] = None,
        add_subtitles: bool = False
    ) -> str:
        """
        执行视频合成

        Args:
            video_results: 视频片段结果列表
            output_filename: 输出文件名
            bgm_path: 背景音乐路径（可选）
            add_subtitles: 是否添加字幕

        Returns:
            最终视频路径
        """
        if not await self.validate_input(video_results):
            raise ValueError("Invalid video results")

        self.logger.info(f"Starting video composition with {len(video_results)} clips")

        try:
            # 按scene_id排序
            video_results = sorted(video_results, key=lambda x: x['scene_id'])

            # 加载视频片段
            clips = self._load_video_clips(video_results)

            # 添加转场效果
            if self.config.get('add_transitions', False):
                clips = self._add_transitions(clips)

            # 拼接视频
            final_clip = concatenate_videoclips(clips, method="compose")

            # 添加背景音乐
            if bgm_path:
                final_clip = self._add_background_music(final_clip, bgm_path)

            # 添加字幕
            if add_subtitles:
                final_clip = self._add_subtitles(final_clip, video_results)

            # 输出最终视频
            output_path = self.output_dir / output_filename
            final_clip.write_videofile(
                str(output_path),
                codec='libx264',
                audio_codec='aac',
                fps=self.config.get('fps', 30),
                preset=self.config.get('preset', 'medium'),
                threads=self.config.get('threads', 4)
            )

            # 清理资源
            final_clip.close()
            for clip in clips:
                clip.close()

            self.logger.info(f"Video composition completed: {output_path}")

            await self.on_complete(str(output_path))
            return str(output_path)

        except Exception as e:
            await self.on_error(e)
            raise

    async def validate_input(self, video_results: List[Dict[str, Any]]) -> bool:
        """验证输入数据"""
        if not video_results:
            return False

        # 检查所有视频文件是否存在
        for result in video_results:
            video_path = result.get('video_path')
            if not video_path or not Path(video_path).exists():
                self.logger.error(f"Video file not found: {video_path}")
                return False

        return True

    def _load_video_clips(self, video_results: List[Dict[str, Any]]) -> List[VideoFileClip]:
        """加载视频片段"""
        clips = []

        for result in video_results:
            video_path = result['video_path']
            self.logger.info(f"Loading clip: {video_path}")

            clip = VideoFileClip(video_path)
            clips.append(clip)

        return clips

    def _add_transitions(self, clips: List[VideoFileClip]) -> List[VideoFileClip]:
        """
        添加转场效果

        支持的转场类型：
        - fade: 淡入淡出
        - crossfade: 交叉淡化
        """
        transition_type = self.config.get('transition_type', 'fade')
        transition_duration = self.config.get('transition_duration', 0.5)

        if transition_type == 'crossfade':
            return self._apply_crossfade(clips, transition_duration)
        elif transition_type == 'fade':
            return self._apply_fade(clips, transition_duration)
        else:
            return clips

    def _apply_fade(
        self,
        clips: List[VideoFileClip],
        duration: float
    ) -> List[VideoFileClip]:
        """应用淡入淡出效果"""
        processed = []

        for clip in clips:
            # 添加淡入淡出
            clip = clip.fadein(duration).fadeout(duration)
            processed.append(clip)

        return processed

    def _apply_crossfade(
        self,
        clips: List[VideoFileClip],
        duration: float
    ) -> List[VideoFileClip]:
        """应用交叉淡化效果"""
        if len(clips) <= 1:
            return clips

        processed = [clips[0].fadein(duration)]

        for i in range(1, len(clips)):
            # 当前片段淡入，前一片段会淡出
            clip = clips[i].fadein(duration)
            processed.append(clip)

        processed[-1] = processed[-1].fadeout(duration)

        return processed

    def _add_background_music(
        self,
        video_clip: VideoFileClip,
        bgm_path: str
    ) -> VideoFileClip:
        """
        添加背景音乐

        Args:
            video_clip: 视频片段
            bgm_path: 背景音乐路径

        Returns:
            添加了BGM的视频片段
        """
        self.logger.info(f"Adding background music: {bgm_path}")

        try:
            audio = AudioFileClip(bgm_path)

            # 如果音乐较短，循环播放
            if audio.duration < video_clip.duration:
                n_loops = int(video_clip.duration / audio.duration) + 1
                audio = audio.loop(n_loops)

            # 截取到视频长度
            audio = audio.subclip(0, video_clip.duration)

            # 降低音量（避免盖过对话）
            audio = audio.volumex(self.config.get('bgm_volume', 0.3))

            # 合并音频
            if video_clip.audio:
                # 混合原音频和BGM
                from moviepy.audio.AudioClip import CompositeAudioClip
                final_audio = CompositeAudioClip([video_clip.audio, audio])
                video_clip = video_clip.set_audio(final_audio)
            else:
                video_clip = video_clip.set_audio(audio)

            return video_clip

        except Exception as e:
            self.logger.error(f"Failed to add BGM: {e}")
            return video_clip

    def _add_subtitles(
        self,
        video_clip: VideoFileClip,
        video_results: List[Dict[str, Any]]
    ) -> VideoFileClip:
        """
        添加字幕

        Args:
            video_clip: 视频片段
            video_results: 视频结果（包含字幕信息）

        Returns:
            添加了字幕的视频片段
        """
        self.logger.info("Adding subtitles")

        # 这里需要根据实际的字幕数据格式实现
        # 示例：假设video_results中包含字幕文本和时间戳

        subtitle_clips = []
        current_time = 0

        for result in video_results:
            # 从scene数据中提取对话
            if 'dialogues' in result:
                for dialogue in result['dialogues']:
                    txt_clip = TextClip(
                        dialogue['content'],
                        fontsize=self.config.get('subtitle_fontsize', 24),
                        color='white',
                        font=self.config.get('subtitle_font', 'Arial'),
                        stroke_color='black',
                        stroke_width=2
                    )

                    # 设置字幕位置和时长
                    txt_clip = txt_clip.set_position(('center', 'bottom'))
                    txt_clip = txt_clip.set_start(current_time)
                    txt_clip = txt_clip.set_duration(dialogue.get('duration', 2.0))

                    subtitle_clips.append(txt_clip)
                    current_time += dialogue.get('duration', 2.0)

        if subtitle_clips:
            # 合成字幕和视频
            video_clip = CompositeVideoClip([video_clip] + subtitle_clips)

        return video_clip
```

---

### 4.3 后期特效处理

创建`utils/video_effects.py`：

```python
from moviepy.editor import VideoFileClip
from moviepy.video.fx import all as vfx
from typing import Optional
import logging

class VideoEffects:
    """视频特效处理工具"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def apply_color_grading(
        self,
        clip: VideoFileClip,
        preset: str = "cinematic"
    ) -> VideoFileClip:
        """
        应用调色预设

        Args:
            clip: 视频片段
            preset: 预设名称（cinematic/warm/cool/vibrant）

        Returns:
            调色后的视频
        """
        if preset == "cinematic":
            # 降低饱和度，增加对比度
            clip = clip.fx(vfx.colorx, 0.9)
        elif preset == "warm":
            # 温暖色调
            clip = clip.fx(vfx.colorx, 1.1)
        elif preset == "cool":
            # 冷色调
            clip = clip.fx(vfx.colorx, 0.8)

        return clip

    def add_vignette(self, clip: VideoFileClip, strength: float = 0.3) -> VideoFileClip:
        """
        添加晕影效果

        Args:
            clip: 视频片段
            strength: 强度（0.0-1.0）

        Returns:
            添加晕影的视频
        """
        # 使用mask_color实现晕影
        # 这里需要自定义实现
        return clip

    def stabilize(self, clip: VideoFileClip) -> VideoFileClip:
        """视频稳定（需要额外的库支持）"""
        # 可以集成vid.stab或其他稳定库
        return clip
```

---

## 模块5：主控Agent协调器

### 5.1 工作流编排

创建`agents/orchestrator_agent.py`：

```python
import asyncio
from typing import Dict, Any, Optional, Callable
from pathlib import Path
from agents.base_agent import BaseAgent
from agents.script_parser_agent import ScriptParserAgent
from agents.image_generator_agent import ImageGenerationAgent
from agents.video_generator_agent import VideoGenerationAgent
from agents.video_composer_agent import VideoComposerAgent
from models.script_models import Script
import logging
import json

class DramaGenerationOrchestrator(BaseAgent):
    """主控Agent - 协调整个短剧生成流程"""

    def __init__(
        self,
        agent_id: str = "orchestrator",
        config: Dict[str, Any] = None
    ):
        super().__init__(agent_id, config or {})
        self.logger = logging.getLogger(__name__)

        # 初始化子Agent
        self.script_parser = ScriptParserAgent()
        self.image_generator = ImageGenerationAgent(config=config.get('image', {}))
        self.video_generator = VideoGenerationAgent(config=config.get('video', {}))
        self.video_composer = VideoComposerAgent(config=config.get('composer', {}))

        # 进度回调
        self.progress_callback: Optional[Callable] = None

    async def execute(
        self,
        script_text: str,
        output_filename: str = "drama.mp4",
        progress_callback: Optional[Callable] = None
    ) -> str:
        """
        执行完整的短剧生成流程

        Args:
            script_text: 剧本文本
            output_filename: 输出文件名
            progress_callback: 进度回调函数

        Returns:
            最终视频文件路径
        """
        self.progress_callback = progress_callback

        try:
            # 步骤1：解析剧本 (10%)
            await self._update_progress(0, "Parsing script...")
            script = await self.script_parser.execute(script_text)
            await self._update_progress(10, f"Script parsed: {script.total_scenes} scenes")

            # 步骤2：生成分镜图片 (10% -> 40%)
            await self._update_progress(10, "Generating storyboard images...")
            image_results = await self.image_generator.execute_concurrent(script.scenes)
            await self._update_progress(40, f"Generated {len(image_results)} images")

            # 步骤3：生成视频片段 (40% -> 70%)
            await self._update_progress(40, "Converting images to videos...")
            video_results = await self.video_generator.execute(image_results, script.scenes)
            await self._update_progress(70, f"Generated {len(video_results)} video clips")

            # 步骤4：合成最终视频 (70% -> 100%)
            await self._update_progress(70, "Composing final video...")
            final_video_path = await self.video_composer.execute(
                video_results,
                output_filename=output_filename,
                bgm_path=self.config.get('bgm_path'),
                add_subtitles=self.config.get('add_subtitles', False)
            )
            await self._update_progress(100, "Completed!")

            # 保存元数据
            await self._save_metadata(script, final_video_path)

            return final_video_path

        except Exception as e:
            self.logger.error(f"Drama generation failed: {e}")
            await self.on_error(e)
            raise

    async def validate_input(self, script_text: str) -> bool:
        """验证输入剧本"""
        return bool(script_text and isinstance(script_text, str))

    async def _update_progress(self, percent: float, message: str):
        """更新进度"""
        self.logger.info(f"Progress: {percent}% - {message}")

        if self.progress_callback:
            if asyncio.iscoroutinefunction(self.progress_callback):
                await self.progress_callback(percent, message)
            else:
                self.progress_callback(percent, message)

    async def _save_metadata(self, script: Script, video_path: str):
        """保存生成元数据"""
        metadata = {
            'script_title': script.title,
            'total_scenes': script.total_scenes,
            'total_duration': script.total_duration,
            'video_path': video_path,
            'config': self.config
        }

        metadata_path = Path(video_path).with_suffix('.json')

        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)

        self.logger.info(f"Metadata saved: {metadata_path}")

    async def close(self):
        """关闭所有子Agent资源"""
        await self.image_generator.close()
        await self.video_generator.close()
```

---

### 5.2 状态管理与断点续传

创建`utils/checkpoint.py`：

```python
import json
from pathlib import Path
from typing import Dict, Any, Optional
from datetime import datetime
import logging

class CheckpointManager:
    """断点续传管理器"""

    def __init__(self, checkpoint_dir: Path = Path("./checkpoints")):
        self.checkpoint_dir = checkpoint_dir
        self.checkpoint_dir.mkdir(parents=True, exist_ok=True)
        self.logger = logging.getLogger(__name__)

    def save_checkpoint(
        self,
        task_id: str,
        stage: str,
        data: Dict[str, Any]
    ) -> Path:
        """
        保存检查点

        Args:
            task_id: 任务ID
            stage: 当前阶段
            data: 要保存的数据

        Returns:
            检查点文件路径
        """
        checkpoint = {
            'task_id': task_id,
            'stage': stage,
            'timestamp': datetime.now().isoformat(),
            'data': data
        }

        checkpoint_file = self.checkpoint_dir / f"{task_id}_{stage}.json"

        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint, f, indent=2, ensure_ascii=False)

        self.logger.info(f"Checkpoint saved: {checkpoint_file}")
        return checkpoint_file

    def load_checkpoint(
        self,
        task_id: str,
        stage: Optional[str] = None
    ) -> Optional[Dict[str, Any]]:
        """
        加载检查点

        Args:
            task_id: 任务ID
            stage: 阶段（None则加载最新）

        Returns:
            检查点数据
        """
        if stage:
            checkpoint_file = self.checkpoint_dir / f"{task_id}_{stage}.json"
        else:
            # 查找最新的检查点
            checkpoints = list(self.checkpoint_dir.glob(f"{task_id}_*.json"))
            if not checkpoints:
                return None

            checkpoint_file = max(checkpoints, key=lambda p: p.stat().st_mtime)

        if not checkpoint_file.exists():
            return None

        with open(checkpoint_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def clear_checkpoints(self, task_id: str):
        """清除任务的所有检查点"""
        for checkpoint_file in self.checkpoint_dir.glob(f"{task_id}_*.json"):
            checkpoint_file.unlink()
            self.logger.info(f"Checkpoint removed: {checkpoint_file}")
```

---

### 5.3 进度监控与回调

创建`utils/progress_monitor.py`：

```python
from typing import Callable, Optional
from dataclasses import dataclass
from datetime import datetime
import asyncio

@dataclass
class ProgressInfo:
    """进度信息"""
    percent: float
    message: str
    timestamp: datetime
    eta: Optional[float] = None  # 预计剩余时间（秒）

class ProgressMonitor:
    """进度监控器"""

    def __init__(self, total_steps: int = 100):
        self.total_steps = total_steps
        self.current_step = 0
        self.start_time = datetime.now()
        self.callbacks: list[Callable] = []

    def register_callback(self, callback: Callable):
        """注册进度回调"""
        self.callbacks.append(callback)

    async def update(self, step: int, message: str):
        """
        更新进度

        Args:
            step: 当前步骤
            message: 进度消息
        """
        self.current_step = step
        percent = (step / self.total_steps) * 100

        # 计算ETA
        elapsed = (datetime.now() - self.start_time).total_seconds()
        if step > 0:
            eta = (elapsed / step) * (self.total_steps - step)
        else:
            eta = None

        progress_info = ProgressInfo(
            percent=percent,
            message=message,
            timestamp=datetime.now(),
            eta=eta
        )

        # 触发回调
        for callback in self.callbacks:
            if asyncio.iscoroutinefunction(callback):
                await callback(progress_info)
            else:
                callback(progress_info)
```

---

## 小结

本部分完成了视频生成和合成的核心功能：

1. **Veo3视频生成模块**：
   - 封装了Veo3 API服务
   - 实现了图片到视频的转换
   - 支持异步任务管理和进度跟踪

2. **视频合成模块**：
   - 集成了FFmpeg和MoviePy
   - 实现了视频拼接、转场、BGM、字幕等功能
   - 提供了丰富的后期处理选项

3. **主控Agent**：
   - 协调所有子Agent的执行
   - 实现了完整的工作流编排
   - 支持断点续传和进度监控

下一部分将提供**完整的使用示例**和**最佳实践指南**。

---

**下一步**：继续阅读**第4部分：使用示例与最佳实践**。
